{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing Clustering Configurations\n",
    "\n",
    "This notebook compares different clustering configurations to find the optimal trade-off\n",
    "between accuracy and computational speed.\n",
    "\n",
    "We compare:\n",
    "\n",
    "- **Number of clusters**: How many typical periods are needed?\n",
    "- **Inner-period segmentation**: Can we reduce timesteps within each cluster?\n",
    "\n",
    "!!! note \"Requirements\"\n",
    "    This notebook requires the `tsam` package: `pip install tsam`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import flixopt as fx\n",
    "\n",
    "fx.CONFIG.notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "District heating system with a full year of hourly data (8760 timesteps):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.generate_example_systems import create_district_heating_system\n",
    "\n",
    "flow_system = create_district_heating_system(duration='quarter')\n",
    "flow_system.connect_and_transform()\n",
    "\n",
    "solver = fx.solvers.HighsSolver(mip_gap=0.01)\n",
    "peak_series = ['HeatDemand(Q_th)|fixed_relative_profile']\n",
    "\n",
    "flow_system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Optimizations\n",
    "\n",
    "Compare full resolution, different cluster counts, and segmentation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "\n",
    "# Full resolution baseline\n",
    "start = timeit.default_timer()\n",
    "fs_full = flow_system.copy()\n",
    "fs_full.name = 'Full'\n",
    "fs_full.optimize(solver)\n",
    "results['Full'] = {'fs': fs_full, 'time': timeit.default_timer() - start, 'timesteps': len(flow_system.timesteps)}\n",
    "\n",
    "# Different cluster counts\n",
    "for n_clusters in [4, 8, 12]:\n",
    "    start = timeit.default_timer()\n",
    "    fs = flow_system.transform.cluster(\n",
    "        n_clusters=n_clusters,\n",
    "        cluster_duration='1D',\n",
    "        time_series_for_high_peaks=peak_series,\n",
    "    )\n",
    "    fs.name = f'{n_clusters} clusters'\n",
    "    fs.optimize(solver)\n",
    "    results[f'{n_clusters} clusters'] = {'fs': fs, 'time': timeit.default_timer() - start, 'timesteps': n_clusters * 24}\n",
    "\n",
    "# Segmentation (8 clusters with 6 segments each)\n",
    "start = timeit.default_timer()\n",
    "fs_seg = flow_system.transform.cluster(\n",
    "    n_clusters=16,\n",
    "    cluster_duration='1D',\n",
    "    n_segments=6,\n",
    "    time_series_for_high_peaks=peak_series,\n",
    ")\n",
    "fs_seg.name = '16x6 segmented'\n",
    "fs_seg.optimize(solver)\n",
    "results['16x6 segmented'] = {'fs': fs_seg, 'time': timeit.default_timer() - start, 'timesteps': 8 * 6}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_cost = results['Full']['fs'].solution['costs'].item()\n",
    "baseline_time = results['Full']['time']\n",
    "\n",
    "summary = pd.DataFrame(\n",
    "    {\n",
    "        name: {\n",
    "            'Timesteps': r['timesteps'],\n",
    "            'Time [s]': r['time'],\n",
    "            'Cost [EUR]': r['fs'].solution['costs'].item(),\n",
    "            'Cost Gap [%]': (r['fs'].solution['costs'].item() - baseline_cost) / max(abs(baseline_cost), 1) * 100,\n",
    "            'CHP [kW]': r['fs'].statistics.sizes['CHP(Q_th)'].item(),\n",
    "            'Storage [kWh]': r['fs'].statistics.sizes['Storage'].item(),\n",
    "            'Speedup': baseline_time / r['time'],\n",
    "        }\n",
    "        for name, r in results.items()\n",
    "    }\n",
    ").T\n",
    "\n",
    "summary.style.format(\n",
    "    {\n",
    "        'Timesteps': '{:.0f}',\n",
    "        'Time [s]': '{:.2f}',\n",
    "        'Cost [EUR]': '{:.0f}',\n",
    "        'Cost Gap [%]': '{:+.1f}',\n",
    "        'CHP [kW]': '{:.1f}',\n",
    "        'Storage [kWh]': '{:.0f}',\n",
    "        'Speedup': '{:.1f}x',\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expand Solutions to Full Resolution\n",
    "\n",
    "Before comparing time series, expand all clustered solutions back to the original timesteps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expand all clustered/segmented solutions\n",
    "expanded = {\n",
    "    'Full': results['Full']['fs'],\n",
    "    '4 clusters': results['4 clusters']['fs'].transform.expand(),\n",
    "    '8 clusters': results['8 clusters']['fs'].transform.expand(),\n",
    "    '12 clusters': results['12 clusters']['fs'].transform.expand(),\n",
    "    '16x6 segmented': results['16x6 segmented']['fs'].transform.expand(),\n",
    "}\n",
    "\n",
    "# Rename for clarity\n",
    "for name, fs in expanded.items():\n",
    "    fs.name = name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Component Sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison = fx.Comparison(list(expanded.values()))\n",
    "comparison.statistics.sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison.statistics.plot.sizes(color='case')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Heat Production\n",
    "\n",
    "Visualize CHP and Boiler flow rates across all configurations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison.solution['CHP(Q_th)|flow_rate'].fxplot.heatmap(title='Heat Production by Configuration')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison.inputs['HeatDemand(Q_th)|fixed_relative_profile'].fxplot.line(\n",
    "    title='Heat Demand by Configuration', colors='viridis'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Storage Operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison.solution['Storage|charge_state'].fxplot.line(color='case', title='Storage State of Charge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison.statistics.plot.storage('Storage').data.sum('time').to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering Quality Metrics\n",
    "\n",
    "RMSE and MAE show how well clustering preserves time series patterns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Collect metrics from clustered systems\n",
    "metrics_list = []\n",
    "for name in ['4 clusters', '8 clusters', '12 clusters']:\n",
    "    fs = results[name]['fs']\n",
    "    df = fs.clustering.metrics.to_dataframe()\n",
    "    df['Config'] = name\n",
    "    metrics_list.append(df)\n",
    "\n",
    "metrics_df = pd.concat(metrics_list)\n",
    "metrics_df.index.name = 'Time Series'\n",
    "metrics_df = metrics_df.reset_index()\n",
    "\n",
    "# Pivot for display\n",
    "metrics_df.pivot(index='Time Series', columns='Config', values='RMSE').style.format('{:.4f}').background_gradient(\n",
    "    cmap='RdYlGn_r', axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Clustering Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['8 clusters']['fs'].clustering.plot.compare(kind='duration_curve')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['8 clusters']['fs'].clustering.plot.heatmap()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segmentation: Variable Segment Durations\n",
    "\n",
    "Segmentation creates variable-length segments that adapt to time series patterns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs_seg = results['16x6 segmented']['fs']\n",
    "\n",
    "# Show segment durations (hours per segment per cluster)\n",
    "fs_seg.timestep_duration.to_pandas().style.format('{:.0f}').background_gradient(cmap='Blues', axis=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize segment durations\n",
    "fs_seg.timestep_duration.fxplot.bar(facet_col='cluster', facet_col_wrap=4, title='Segment Durations per Cluster')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommendations\n",
    "\n",
    "Based on this comparison:\n",
    "\n",
    "1. **8 clusters** provides good accuracy (~7% cost gap) with 5x speedup\n",
    "2. **Segmentation** provides additional reduction with acceptable accuracy loss\n",
    "3. **4 clusters** may miss demand patterns, leading to undersized or oversized components\n",
    "\n",
    "### When to use segmentation:\n",
    "\n",
    "- Large problems where even clustered optimization is slow\n",
    "- Preliminary design studies where speed matters more than precision\n",
    "- Sensitivity analyses requiring many optimization runs\n",
    "\n",
    "### Best practice:\n",
    "\n",
    "- Always use `time_series_for_high_peaks` to capture extreme demand days\n",
    "- Use `expand_solution()` to validate results at full resolution"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
