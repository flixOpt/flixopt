{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Aggregation\n",
    "\n",
    "Speed up large problems with time series aggregation techniques.\n",
    "\n",
    "This notebook introduces:\n",
    "\n",
    "- **Resampling**: Reduce time resolution (e.g., hourly → 4-hourly)\n",
    "- **Two-stage optimization**: Size with reduced data, dispatch at full resolution\n",
    "- **Speed vs. accuracy trade-offs**: When to use each technique"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "import flixopt as fx\n",
    "\n",
    "fx.CONFIG.notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## Load the FlowSystem\n",
    "\n",
    "We use a pre-built district heating system with real-world time series data (one month at 15-min resolution):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Generate example data if not present (for local development)\n",
    "data_file = Path('data/district_heating_system.nc4')\n",
    "if not data_file.exists():\n",
    "    from data.generate_example_systems import create_district_heating_system\n",
    "\n",
    "    fs = create_district_heating_system()\n",
    "    fs.to_netcdf(data_file)\n",
    "\n",
    "# Load the district heating system (real data from Zeitreihen2020.csv)\n",
    "flow_system = fx.FlowSystem.from_netcdf(data_file)\n",
    "\n",
    "timesteps = flow_system.timesteps\n",
    "print(f'Loaded FlowSystem: {len(timesteps)} timesteps ({len(timesteps) / 96:.0f} days at 15-min resolution)')\n",
    "print(f'Components: {list(flow_system.components.keys())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize first week of data\n",
    "heat_demand = flow_system.components['HeatDemand'].inputs[0].fixed_relative_profile\n",
    "electricity_price = flow_system.components['GridBuy'].outputs[0].effects_per_flow_hour['costs']\n",
    "\n",
    "fig = make_subplots(rows=2, cols=1, shared_xaxes=True, vertical_spacing=0.1)\n",
    "\n",
    "fig.add_trace(go.Scatter(x=timesteps[:672], y=heat_demand.values[:672], name='Heat Demand'), row=1, col=1)\n",
    "fig.add_trace(go.Scatter(x=timesteps[:672], y=electricity_price.values[:672], name='Electricity Price'), row=2, col=1)\n",
    "\n",
    "fig.update_layout(height=400, title='First Week of Data')\n",
    "fig.update_yaxes(title_text='Heat Demand [MW]', row=1, col=1)\n",
    "fig.update_yaxes(title_text='El. Price [€/MWh]', row=2, col=1)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## Technique 1: Resampling\n",
    "\n",
    "Reduce time resolution to speed up optimization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "solver = fx.solvers.HighsSolver(mip_gap=0.01)\n",
    "\n",
    "# Resample from 15-min to 4h resolution\n",
    "fs_resampled = flow_system.transform.resample('4h')\n",
    "\n",
    "reduction = (1 - len(fs_resampled.timesteps) / len(flow_system.timesteps)) * 100\n",
    "print(f'Resampled: {len(flow_system.timesteps)} → {len(fs_resampled.timesteps)} timesteps ({reduction:.0f}% reduction)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize resampled system\n",
    "start = timeit.default_timer()\n",
    "fs_resampled.optimize(solver)\n",
    "time_resampled = timeit.default_timer() - start\n",
    "\n",
    "print(f'Resampled: {time_resampled:.1f}s, {fs_resampled.solution[\"costs\"].item():,.0f} €')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "## Technique 2: Two-Stage Optimization\n",
    "\n",
    "1. **Stage 1**: Size components with resampled data (fast)\n",
    "2. **Stage 2**: Fix sizes and optimize dispatch at full resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stage 1: Sizing with resampled data\n",
    "start = timeit.default_timer()\n",
    "fs_sizing = flow_system.transform.resample('4h')\n",
    "fs_sizing.optimize(solver)\n",
    "time_stage1 = timeit.default_timer() - start\n",
    "\n",
    "sizes = {k: float(v.item()) for k, v in fs_sizing.statistics.sizes.items()}\n",
    "print(\n",
    "    f'Stage 1 (sizing): {time_stage1:.1f}s → CHP {sizes[\"CHP(Q_th)\"]:.0f}, Boiler {sizes[\"Boiler(Q_th)\"]:.0f}, Storage {sizes[\"Storage\"]:.0f}'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stage 2: Dispatch at full resolution with fixed sizes\n",
    "start = timeit.default_timer()\n",
    "fs_dispatch = flow_system.transform.fix_sizes(fs_sizing.statistics.sizes)\n",
    "fs_dispatch.optimize(solver)\n",
    "time_stage2 = timeit.default_timer() - start\n",
    "\n",
    "print(\n",
    "    f'Stage 2 (dispatch): {time_stage2:.1f}s, {fs_dispatch.solution[\"costs\"].item():,.0f} € (total: {time_stage1 + time_stage2:.1f}s)'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## Technique 3: Full Optimization (Baseline)\n",
    "\n",
    "For comparison, solve the full problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timeit.default_timer()\n",
    "fs_full = flow_system.copy()\n",
    "fs_full.optimize(solver)\n",
    "time_full = timeit.default_timer() - start\n",
    "\n",
    "print(f'Full optimization: {time_full:.1f}s, {fs_full.solution[\"costs\"].item():,.0f} €')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "## Compare Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect results\n",
    "results = {\n",
    "    'Full (baseline)': {\n",
    "        'Time [s]': time_full,\n",
    "        'Cost [€]': fs_full.solution['costs'].item(),\n",
    "        'CHP Size [MW]': fs_full.statistics.sizes['CHP(Q_th)'].item(),\n",
    "        'Boiler Size [MW]': fs_full.statistics.sizes['Boiler(Q_th)'].item(),\n",
    "        'Storage Size [MWh]': fs_full.statistics.sizes['Storage'].item(),\n",
    "    },\n",
    "    'Resampled (4h)': {\n",
    "        'Time [s]': time_resampled,\n",
    "        'Cost [€]': fs_resampled.solution['costs'].item(),\n",
    "        'CHP Size [MW]': fs_resampled.statistics.sizes['CHP(Q_th)'].item(),\n",
    "        'Boiler Size [MW]': fs_resampled.statistics.sizes['Boiler(Q_th)'].item(),\n",
    "        'Storage Size [MWh]': fs_resampled.statistics.sizes['Storage'].item(),\n",
    "    },\n",
    "    'Two-Stage': {\n",
    "        'Time [s]': time_stage1 + time_stage2,\n",
    "        'Cost [€]': fs_dispatch.solution['costs'].item(),\n",
    "        'CHP Size [MW]': fs_dispatch.statistics.sizes['CHP(Q_th)'].item(),\n",
    "        'Boiler Size [MW]': fs_dispatch.statistics.sizes['Boiler(Q_th)'].item(),\n",
    "        'Storage Size [MWh]': fs_dispatch.statistics.sizes['Storage'].item(),\n",
    "    },\n",
    "}\n",
    "\n",
    "comparison = pd.DataFrame(results).T\n",
    "\n",
    "# Add relative metrics\n",
    "baseline_cost = comparison.loc['Full (baseline)', 'Cost [€]']\n",
    "baseline_time = comparison.loc['Full (baseline)', 'Time [s]']\n",
    "comparison['Cost Gap [%]'] = ((comparison['Cost [€]'] - baseline_cost) / baseline_cost * 100).round(2)\n",
    "comparison['Speedup'] = (baseline_time / comparison['Time [s]']).round(1)\n",
    "\n",
    "comparison.style.format(\n",
    "    {\n",
    "        'Time [s]': '{:.2f}',\n",
    "        'Cost [€]': '{:,.0f}',\n",
    "        'CHP Size [MW]': '{:.1f}',\n",
    "        'Boiler Size [MW]': '{:.1f}',\n",
    "        'Storage Size [MWh]': '{:.0f}',\n",
    "        'Cost Gap [%]': '{:.2f}',\n",
    "        'Speedup': '{:.1f}x',\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "## Visual Comparison: Heat Balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full optimization heat balance\n",
    "fs_full.statistics.plot.balance('Heat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two-stage optimization heat balance\n",
    "fs_dispatch.statistics.plot.balance('Heat')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "### Energy Flow Sankey (Full Optimization)\n",
    "\n",
    "A Sankey diagram visualizes the total energy flows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs_full.statistics.plot.sankey.flows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "## When to Use Each Technique\n",
    "\n",
    "| Technique | Best For | Trade-off |\n",
    "|-----------|----------|------------|\n",
    "| **Full optimization** | Final results, small problems | Slowest, most accurate |\n",
    "| **Resampling** | Quick screening, trend analysis | Fast, loses temporal detail |\n",
    "| **Two-stage** | Investment decisions, large problems | Good balance of speed and accuracy |\n",
    "| **Clustering** | Preserves extreme periods | Requires `tsam` package |\n",
    "\n",
    "### Resampling Options\n",
    "\n",
    "```python\n",
    "# Different resolutions\n",
    "fs_2h = flow_system.transform.resample('2h')   # 2-hourly\n",
    "fs_4h = flow_system.transform.resample('4h')   # 4-hourly\n",
    "fs_daily = flow_system.transform.resample('1D')  # Daily\n",
    "\n",
    "# Different aggregation methods\n",
    "fs_mean = flow_system.transform.resample('4h', method='mean')  # Default\n",
    "fs_max = flow_system.transform.resample('4h', method='max')    # Preserve peaks\n",
    "```\n",
    "\n",
    "### Two-Stage Workflow\n",
    "\n",
    "```python\n",
    "# Stage 1: Sizing\n",
    "fs_sizing = flow_system.transform.resample('4h')\n",
    "fs_sizing.optimize(solver)\n",
    "\n",
    "# Stage 2: Dispatch\n",
    "fs_dispatch = flow_system.transform.fix_sizes(fs_sizing.statistics.sizes)\n",
    "fs_dispatch.optimize(solver)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "You learned how to:\n",
    "\n",
    "- Use **`transform.resample()`** to reduce time resolution\n",
    "- Apply **two-stage optimization** for large investment problems\n",
    "- Use **`transform.fix_sizes()`** to lock in investment decisions\n",
    "- Compare **speed vs. accuracy** trade-offs\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **Start fast**: Use resampling for initial exploration\n",
    "2. **Iterate**: Refine with two-stage optimization\n",
    "3. **Validate**: Run full optimization for final results\n",
    "4. **Monitor**: Check cost gaps to ensure acceptable accuracy\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- **[08b-Rolling Horizon](08b-rolling-horizon.ipynb)**: For operational problems, decompose time into sequential segments\n",
    "- **[08c-Clustering](08c-clustering.ipynb)**: Use typical periods with the `tsam` package\n",
    "\n",
    "### Further Reading\n",
    "\n",
    "- For clustering with typical periods, see `transform.cluster()` (requires `tsam` package)\n",
    "- For time selection, see `transform.sel()` and `transform.isel()`"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
