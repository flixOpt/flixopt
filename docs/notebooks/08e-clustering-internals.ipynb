{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Clustering Internals\n",
    "\n",
    "Understanding the data structures behind time series clustering.\n",
    "\n",
    "This notebook demonstrates:\n",
    "\n",
    "- **`Clustering` dataclass**: The simple data structure storing clustering metadata\n",
    "- **Key properties**: `n_clusters`, `timesteps_per_cluster`, `cluster_assignments`, `cluster_weights`\n",
    "- **Visualization**: Using `clustering.plot.heatmap()` to understand cluster structure\n",
    "- **Data expansion**: Using `expand_data()` to map aggregated data back to original timesteps\n",
    "\n",
    "!!! note \"Prerequisites\"\n",
    "    This notebook assumes familiarity with [08c-clustering](08c-clustering.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.generate_example_systems import create_district_heating_system\n",
    "\n",
    "import flixopt as fx\n",
    "\n",
    "fx.CONFIG.notebook()\n",
    "\n",
    "flow_system = create_district_heating_system()\n",
    "flow_system.connect_and_transform()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Create Clustering\n",
    "\n",
    "After calling `cluster()`, metadata is stored in `fs.clustering`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tsam\n",
    "\n",
    "fs_clustered = flow_system.transform.cluster(\n",
    "    n_clusters=8,\n",
    "    cluster_duration='1D',\n",
    "    extremes=tsam.ExtremeConfig(max_value=['HeatDemand(Q_th)|fixed_relative_profile']),\n",
    ")\n",
    "\n",
    "fs_clustered.clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## The `Clustering` Dataclass\n",
    "\n",
    "The `Clustering` class is a simple Python dataclass that stores all clustering metadata:\n",
    "\n",
    "| Field | Type | Description |\n",
    "|-------|------|-------------|\n",
    "| `cluster_assignments` | `xr.DataArray` | Maps original segments → cluster ID |\n",
    "| `cluster_weights` | `xr.DataArray` | Count of original segments per cluster |\n",
    "| `original_timesteps` | `pd.DatetimeIndex` | Original full-resolution time index |\n",
    "| `predefined` | `PredefinedConfig` | Config to transfer clustering to another system |\n",
    "| `metrics` | `xr.Dataset` | RMSE, MAE per time series |\n",
    "\n",
    "All other properties (like `n_clusters`, `timesteps_per_cluster`) are **derived from the data**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core data: cluster assignments\n",
    "# Shape: [original_cluster] - maps each original segment (e.g., day) to a cluster ID\n",
    "clustering = fs_clustered.clustering\n",
    "print('cluster_assignments:')\n",
    "print(clustering.cluster_assignments)\n",
    "print(f'\\nExample: Day 0 → Cluster {int(clustering.cluster_assignments[0].item())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core data: cluster weights (occurrence counts)\n",
    "# Shape: [cluster] - how many original segments each cluster represents\n",
    "print('cluster_weights:')\n",
    "print(clustering.cluster_weights)\n",
    "print(\n",
    "    f'\\nSum of weights: {int(clustering.cluster_weights.sum().item())} (= {clustering.n_original_clusters} original days)'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## Derived Properties\n",
    "\n",
    "Properties are computed from the data, not stored separately:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'n_clusters:            {clustering.n_clusters}')\n",
    "print(f'n_original_clusters:   {clustering.n_original_clusters}')\n",
    "print(f'timesteps_per_cluster: {clustering.timesteps_per_cluster}')\n",
    "print(f'original_timesteps:    {len(clustering.original_timesteps)} timesteps')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "## Clustering Quality Metrics\n",
    "\n",
    "The `metrics` property contains RMSE and MAE per time series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View metrics as a DataFrame\n",
    "clustering.metrics.to_dataframe().style.format('{:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "## Visualizing Cluster Structure\n",
    "\n",
    "The `.plot.heatmap()` method visualizes which days belong to which cluster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap shows cluster assignments for each original period\n",
    "clustering.plot.heatmap()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "## Expanding Aggregated Data\n",
    "\n",
    "The `Clustering.expand_data()` method maps clustered (aggregated) data back to original timesteps.\n",
    "This is useful for:\n",
    "- Comparing clustering results before optimization\n",
    "- Expanding solution variables after optimization (via `transform.expand()`)\n",
    "\n",
    "The method uses the `cluster_assignments` to repeat each cluster's data for all original segments it represents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "\n",
    "# Create some example clustered data (n_clusters × timesteps_per_cluster)\n",
    "n_clusters = clustering.n_clusters\n",
    "timesteps_per_cluster = clustering.timesteps_per_cluster\n",
    "\n",
    "# Example: random values for each cluster\n",
    "clustered_data = xr.DataArray(\n",
    "    np.random.rand(n_clusters, timesteps_per_cluster),\n",
    "    dims=['cluster', 'time'],\n",
    "    coords={\n",
    "        'cluster': range(n_clusters),\n",
    "        'time': fs_clustered.timesteps,\n",
    "    },\n",
    ")\n",
    "\n",
    "print(f'Clustered data shape: {clustered_data.shape}')\n",
    "print(f'  - {n_clusters} clusters')\n",
    "print(f'  - {timesteps_per_cluster} timesteps per cluster')\n",
    "\n",
    "# Expand back to original resolution\n",
    "expanded = clustering.expand_data(clustered_data)\n",
    "\n",
    "print(f'\\nExpanded data shape: {expanded.shape}')\n",
    "print(f'  - {len(expanded.time)} total timesteps (original resolution)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "## Transferring Clustering\n",
    "\n",
    "The `predefined` property contains a `PredefinedConfig` that can transfer the clustering to another FlowSystem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the predefined config\n",
    "print(f'predefined type: {type(clustering.predefined).__name__}')\n",
    "print(clustering.predefined)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "## Cluster Weights\n",
    "\n",
    "Each representative timestep has a weight equal to the number of original periods it represents.\n",
    "This ensures operational costs scale correctly:\n",
    "\n",
    "$$\\text{Objective} = \\sum_{t \\in \\text{typical}} w_t \\cdot c_t$$\n",
    "\n",
    "The weights sum to the original segment count:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Sum of cluster_weights: {int(clustering.cluster_weights.sum().item())}')\n",
    "print(f'Original segments:      {clustering.n_original_clusters}')\n",
    "print('\\nFlowSystem cluster_weight (per-timestep):')\n",
    "print(f'  Shape: {fs_clustered.cluster_weight.shape}')\n",
    "print(f'  Sum:   {fs_clustered.cluster_weight.sum().item():.0f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### The `Clustering` Dataclass\n",
    "\n",
    "| Field | Type | Description |\n",
    "|-------|------|-------------|\n",
    "| `cluster_assignments` | `xr.DataArray` | Maps original segments → cluster ID |\n",
    "| `cluster_weights` | `xr.DataArray` | Count of original segments per cluster |\n",
    "| `original_timesteps` | `pd.DatetimeIndex` | Original full-resolution time index |\n",
    "| `predefined` | `PredefinedConfig` | Config to transfer clustering to another system |\n",
    "| `metrics` | `xr.Dataset` | RMSE, MAE per time series |\n",
    "\n",
    "### Derived Properties\n",
    "\n",
    "| Property | Type | Description |\n",
    "|----------|------|-------------|\n",
    "| `n_clusters` | `int` | Number of clusters |\n",
    "| `n_original_clusters` | `int` | Number of original segments |\n",
    "| `timesteps_per_cluster` | `int` | Timesteps per cluster |\n",
    "| `cluster_order` | `xr.DataArray` | Alias for `cluster_assignments` |\n",
    "\n",
    "### Key Methods\n",
    "\n",
    "| Method | Description |\n",
    "|--------|-------------|\n",
    "| `expand_data(data)` | Expand clustered data to original timesteps |\n",
    "| `get_timestep_mapping()` | Get array mapping original → clustered timesteps |\n",
    "| `to_reference()` | Serialize to dict + DataArrays for IO |\n",
    "| `from_reference()` | Reconstruct from serialized form |\n",
    "| `plot.heatmap()` | Visualize cluster assignments |\n",
    "\n",
    "### IO Serialization\n",
    "\n",
    "The `Clustering` class supports full roundtrip serialization:\n",
    "\n",
    "```python\n",
    "# Serialize\n",
    "ref, arrays = clustering.to_reference()\n",
    "\n",
    "# Deserialize\n",
    "clustering = Clustering.from_reference(ref, arrays)\n",
    "```\n",
    "\n",
    "This is used internally by `FlowSystem.to_netcdf()` and `FlowSystem.from_netcdf()`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
