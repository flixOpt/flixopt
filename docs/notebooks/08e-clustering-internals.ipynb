{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Clustering Internals\n",
    "\n",
    "Understanding the data structures and visualization tools behind time series clustering.\n",
    "\n",
    "This notebook demonstrates:\n",
    "\n",
    "- **Data structure**: The `Clustering` class that stores all clustering information\n",
    "- **Plot accessor**: Built-in visualizations via `.plot`\n",
    "- **Data expansion**: Using `expand_data()` to map aggregated data back to original timesteps\n",
    "- **IO workflow**: What's preserved and lost when saving/loading clustered systems\n",
    "\n",
    "!!! note \"Requirements\"\n",
    "    This notebook requires the `tsam` package for time series aggregation.\n",
    "    Install with: `pip install \"flixopt[full]\"`\n",
    "\n",
    "!!! note \"Prerequisites\"\n",
    "    This notebook assumes familiarity with [08c-clustering](08c-clustering.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.generate_example_systems import create_district_heating_system\n",
    "\n",
    "import flixopt as fx\n",
    "\n",
    "fx.CONFIG.notebook()\n",
    "\n",
    "flow_system = create_district_heating_system()\n",
    "flow_system.connect_and_transform()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Clustering Metadata\n",
    "\n",
    "After calling `cluster()`, metadata is stored in `fs.clustering`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsam import ExtremeConfig\n",
    "\n",
    "fs_clustered = flow_system.transform.cluster(\n",
    "    n_clusters=8,\n",
    "    cluster_duration='1D',\n",
    "    extremes=ExtremeConfig(\n",
    "        method='new_cluster', max_value=['HeatDemand(Q_th)|fixed_relative_profile'], preserve_n_clusters=True\n",
    "    ),\n",
    ")\n",
    "\n",
    "fs_clustered.clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "The `Clustering` object contains:\n",
    "- **`cluster_assignments`**: Which cluster each original period maps to\n",
    "- **`cluster_occurrences`**: How many original periods each cluster represents\n",
    "- **`timestep_mapping`**: Maps each original timestep to its representative\n",
    "- **`original_data`** / **`aggregated_data`**: The data before and after clustering\n",
    "- **`results`**: `ClusteringResults` object with xarray-like interface (`.dims`, `.coords`, `.sel()`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster order shows which cluster each original period maps to\n",
    "fs_clustered.clustering.cluster_assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster occurrences shows how many original periods each cluster represents\n",
    "fs_clustered.clustering.cluster_occurrences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## Visualizing Clustering\n",
    "\n",
    "The `.plot` accessor provides built-in visualizations for understanding clustering results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare original vs aggregated data as timeseries\n",
    "# By default, plots all time-varying variables\n",
    "fs_clustered.clustering.plot.compare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a different approach of visualizing the data using normalize heatmaps\n",
    "ds = fs_clustered.clustering.plot.compare(data_only=True).data\n",
    "\n",
    "ds_normalized = (ds - ds.min()) / (ds.max() - ds.min())\n",
    "ds_normalized.to_array().plotly.imshow(\n",
    "    x='time',\n",
    "    animation_frame='representation',\n",
    "    zmin=0,\n",
    "    zmax=1,\n",
    "    color_continuous_scale='viridis',\n",
    "    title='Normalized Comparison',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare specific variables only\n",
    "fs_clustered.clustering.plot.compare(variables='HeatDemand(Q_th)|fixed_relative_profile')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duration curves show how well the aggregated data preserves the distribution\n",
    "fs_clustered.clustering.plot.compare(kind='duration_curve').data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View typical period profiles for each cluster\n",
    "# Each line represents a cluster's representative day\n",
    "fs_clustered.clustering.plot.clusters(variables='HeatDemand(Q_th)|fixed_relative_profile', color='cluster')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap shows cluster assignments for each original period\n",
    "fs_clustered.clustering.plot.heatmap()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "## Expanding Aggregated Data\n",
    "\n",
    "The `Clustering.expand_data()` method maps aggregated data back to original timesteps.\n",
    "This is useful for comparing clustering results before optimization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get original and aggregated data\n",
    "clustering = fs_clustered.clustering\n",
    "original = clustering.original_data['HeatDemand(Q_th)|fixed_relative_profile']\n",
    "aggregated = clustering.aggregated_data['HeatDemand(Q_th)|fixed_relative_profile']\n",
    "\n",
    "# Expand aggregated data back to original timesteps\n",
    "expanded = clustering.expand_data(aggregated)\n",
    "\n",
    "print(f'Original:   {len(original.time)} timesteps')\n",
    "print(f'Aggregated: {len(aggregated.time)} timesteps')\n",
    "print(f'Expanded:   {len(expanded.time)} timesteps')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "| Property | Description |\n",
    "|----------|-------------|\n",
    "| `clustering.n_clusters` | Number of representative clusters |\n",
    "| `clustering.timesteps_per_cluster` | Timesteps in each cluster period |\n",
    "| `clustering.cluster_assignments` | Maps original periods to clusters |\n",
    "| `clustering.cluster_occurrences` | Count of original periods per cluster |\n",
    "| `clustering.timestep_mapping` | Maps original timesteps to representative indices |\n",
    "| `clustering.original_data` | Dataset before clustering |\n",
    "| `clustering.aggregated_data` | Dataset after clustering |\n",
    "| `clustering.results` | `ClusteringResults` with xarray-like interface |\n",
    "\n",
    "### ClusteringResults (xarray-like)\n",
    "\n",
    "Access the underlying tsam results via `clustering.results`:\n",
    "\n",
    "```python\n",
    "# Dimension info (like xarray)\n",
    "clustering.results.dims      # ('period', 'scenario') or ()\n",
    "clustering.results.coords    # {'period': [2020, 2030], 'scenario': ['high', 'low']}\n",
    "\n",
    "# Select specific result (like xarray)\n",
    "clustering.results.sel(period=2020, scenario='high')   # Label-based\n",
    "clustering.results.isel(period=0, scenario=1)          # Index-based\n",
    "```\n",
    "\n",
    "### Plot Accessor Methods\n",
    "\n",
    "| Method | Description |\n",
    "|--------|-------------|\n",
    "| `plot.compare()` | Compare original vs aggregated data (timeseries) |\n",
    "| `plot.compare(kind='duration_curve')` | Compare as duration curves |\n",
    "| `plot.clusters()` | View each cluster's profile |\n",
    "| `plot.heatmap()` | Visualize cluster assignments |\n",
    "\n",
    "### Key Parameters\n",
    "\n",
    "```python\n",
    "# Compare with options\n",
    "clustering.plot.compare(\n",
    "    variables='Demand|profile',       # Single variable, list, or None (all)\n",
    "    kind='timeseries',                # 'timeseries' or 'duration_curve'\n",
    "    select={'scenario': 'Base'},      # xarray-style selection\n",
    "    colors='viridis',                 # Colorscale name, list, or dict\n",
    "    facet_col='period',               # Facet by period if present\n",
    "    facet_row='scenario',             # Facet by scenario if present\n",
    ")\n",
    "\n",
    "# Heatmap shows cluster assignments (no variable needed)\n",
    "clustering.plot.heatmap()\n",
    "\n",
    "# Expand aggregated data to original timesteps\n",
    "expanded = clustering.expand_data(aggregated_data)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "## Cluster Weights\n",
    "\n",
    "Each representative timestep has a weight equal to the number of original periods it represents.\n",
    "This ensures operational costs scale correctly:\n",
    "\n",
    "$$\\text{Objective} = \\sum_{t \\in \\text{typical}} w_t \\cdot c_t$$\n",
    "\n",
    "The weights sum to the original timestep count:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Sum of weights: {fs_clustered.cluster_weight.sum().item():.0f}')\n",
    "print(f'Original timesteps: {len(flow_system.timesteps)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "## Solution Expansion\n",
    "\n",
    "After optimization, `expand()` maps results back to full resolution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "solver = fx.solvers.HighsSolver(mip_gap=0.01, log_to_console=False)\n",
    "fs_clustered.optimize(solver)\n",
    "\n",
    "fs_expanded = fs_clustered.transform.expand()\n",
    "\n",
    "print(f'Clustered: {len(fs_clustered.timesteps)} timesteps')\n",
    "print(f'Expanded:  {len(fs_expanded.timesteps)} timesteps')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "## IO Workflow\n",
    "\n",
    "When saving and loading a clustered FlowSystem, most clustering information is preserved.\n",
    "However, some methods that access tsam's internal `AggregationResult` objects are not available after IO.\n",
    "\n",
    "### What's Preserved After IO\n",
    "\n",
    "- **Structure**: `n_clusters`, `timesteps_per_cluster`, `dims`, `coords`\n",
    "- **Mappings**: `cluster_assignments`, `cluster_occurrences`, `timestep_mapping`\n",
    "- **Data**: `original_data`, `aggregated_data`\n",
    "- **Original timesteps**: `original_timesteps`\n",
    "- **Results structure**: `results.sel()`, `results.isel()` for `ClusteringResult` access\n",
    "\n",
    "### What's Lost After IO\n",
    "\n",
    "- **`clustering.sel()`**: Accessing full `AggregationResult` objects\n",
    "- **`clustering.items()`**: Iterating over `AggregationResult` objects\n",
    "- **tsam internals**: `AggregationResult.accuracy`, `AggregationResult.plot`, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before IO: Full tsam access is available\n",
    "result = fs_clustered.clustering.sel()  # Get the AggregationResult\n",
    "print(f'Before IO - AggregationResult available: {type(result).__name__}')\n",
    "print(f'  - n_clusters: {result.n_clusters}')\n",
    "print(f'  - accuracy.rmse (mean): {result.accuracy.rmse.mean():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save and load the clustered system\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "\n",
    "try:\n",
    "    with tempfile.TemporaryDirectory() as tmpdir:\n",
    "        path = Path(tmpdir) / 'clustered_system.nc'\n",
    "        fs_clustered.to_netcdf(path)\n",
    "        fs_loaded = fx.FlowSystem.from_netcdf(path)\n",
    "\n",
    "    # Structure is preserved\n",
    "    print('After IO - Structure preserved:')\n",
    "    print(f'  - n_clusters: {fs_loaded.clustering.n_clusters}')\n",
    "    print(f'  - dims: {fs_loaded.clustering.dims}')\n",
    "    print(f'  - original_data variables: {list(fs_loaded.clustering.original_data.data_vars)[:3]}...')\n",
    "except OSError as e:\n",
    "    print(f'Note: NetCDF save/load skipped due to environment issue: {type(e).__name__}')\n",
    "    print('This can happen in some CI environments. The functionality works locally.')\n",
    "    fs_loaded = fs_clustered  # Use original for subsequent cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After IO: sel() raises ValueError because AggregationResult is not preserved\n",
    "try:\n",
    "    fs_loaded.clustering.sel()\n",
    "except ValueError as e:\n",
    "    print('After IO - sel() raises ValueError:')\n",
    "    print(f'  \"{e}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key operations still work after IO:\n",
    "# - Optimization\n",
    "# - Expansion back to full resolution\n",
    "# - Accessing original_data and aggregated_data\n",
    "\n",
    "fs_loaded.optimize(solver)\n",
    "fs_loaded_expanded = fs_loaded.transform.expand()\n",
    "\n",
    "print('Loaded system can still be:')\n",
    "print(f'  - Optimized: {fs_loaded.solution is not None}')\n",
    "print(f'  - Expanded: {len(fs_loaded_expanded.timesteps)} timesteps')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "### IO Workflow Summary\n",
    "\n",
    "```\n",
    "┌─────────────────┐    to_netcdf()     ┌─────────────────┐\n",
    "│  fs_clustered   │ ─────────────────► │   NetCDF file   │\n",
    "│                 │                    │                 │\n",
    "│ ✓ clustering    │                    │ ✓ structure     │\n",
    "│ ✓ sel()         │                    │ ✓ mappings      │\n",
    "│ ✓ items()       │                    │ ✓ data          │\n",
    "│ ✓ AggregationResult                  │ ✗ AggregationResult\n",
    "└─────────────────┘                    └─────────────────┘\n",
    "                                              │\n",
    "                                              │ from_netcdf()\n",
    "                                              ▼\n",
    "                                       ┌─────────────────┐\n",
    "                                       │   fs_loaded     │\n",
    "                                       │                 │\n",
    "                                       │ ✓ optimize()    │\n",
    "                                       │ ✓ expand()      │\n",
    "                                       │ ✓ original_data │\n",
    "                                       │ ✗ sel()         │\n",
    "                                       │ ✗ items()       │\n",
    "                                       └─────────────────┘\n",
    "```\n",
    "\n",
    "!!! tip \"Best Practice\"\n",
    "    If you need tsam's `AggregationResult` for analysis (accuracy metrics, built-in plots),\n",
    "    do this **before** saving the FlowSystem. After loading, the core workflow\n",
    "    (optimize → expand) works normally."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "### Reducing File Size\n",
    "\n",
    "For smaller files (~38% reduction), use `include_original_data=False` when saving.\n",
    "This disables `plot.compare()` after loading, but the core workflow still works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "from pathlib import Path\n",
    "\n",
    "# Compare file sizes with and without original_data\n",
    "try:\n",
    "    with tempfile.TemporaryDirectory() as tmpdir:\n",
    "        path_full = Path(tmpdir) / 'full.nc'\n",
    "        path_small = Path(tmpdir) / 'small.nc'\n",
    "\n",
    "        fs_clustered.to_netcdf(path_full, include_original_data=True)\n",
    "        fs_clustered.to_netcdf(path_small, include_original_data=False)\n",
    "\n",
    "        size_full = path_full.stat().st_size / 1024\n",
    "        size_small = path_small.stat().st_size / 1024\n",
    "\n",
    "    print(f'With original_data:    {size_full:.1f} KB')\n",
    "    print(f'Without original_data: {size_small:.1f} KB')\n",
    "    print(f'Size reduction: {(1 - size_small / size_full) * 100:.0f}%')\n",
    "except OSError as e:\n",
    "    print(f'Note: File size comparison skipped due to environment issue: {type(e).__name__}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
