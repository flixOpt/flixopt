{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# External Clustering\n",
    "\n",
    "This notebook demonstrates different ways to apply clustering to a FlowSystem:\n",
    "\n",
    "1. **Built-in clustering** - Let flixopt handle everything via `transform.cluster()`\n",
    "2. **External tsam** - Run tsam yourself on a data subset and pass results to flixopt\n",
    "3. **Custom indices** - Provide your own cluster assignments directly\n",
    "\n",
    "The latter two options are useful when:\n",
    "- You want to cluster on a subset of time series (faster tsam computation)\n",
    "- You have custom clustering algorithms\n",
    "- You want to reuse clustering results across multiple FlowSystems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xarray as xr\n",
    "\n",
    "import flixopt as fx\n",
    "\n",
    "fx.CONFIG.notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load a Pre-built FlowSystem\n",
    "\n",
    "We'll use the district heating system from the data directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Generate example data if not present\n",
    "data_file = Path('data/district_heating_system.nc4')\n",
    "if not data_file.exists():\n",
    "    from data.generate_example_systems import create_district_heating_system\n",
    "\n",
    "    fs = create_district_heating_system()\n",
    "    fs.to_netcdf(data_file)\n",
    "\n",
    "# Load the FlowSystem\n",
    "flow_system = fx.FlowSystem.from_netcdf(data_file)\n",
    "print(f'Loaded FlowSystem: {len(flow_system.timesteps)} timesteps ({len(flow_system.timesteps) / 96:.0f} days)')\n",
    "print(f'Components: {list(flow_system.components.keys())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract key time series from the FlowSystem for later use\n",
    "heat_demand = flow_system.components['HeatDemand'].inputs[0].fixed_relative_profile\n",
    "elec_price = flow_system.components['GridBuy'].outputs[0].effects_per_flow_hour['costs']\n",
    "\n",
    "print(f'Heat demand shape: {heat_demand.shape}')\n",
    "print(f'Electricity price shape: {elec_price.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline: solve without clustering\n",
    "solver = fx.solvers.HighsSolver(mip_gap=0.01, log_to_console=False)\n",
    "fs_baseline = flow_system.copy()\n",
    "fs_baseline.optimize(solver)\n",
    "print(f'Baseline cost (no clustering): {fs_baseline.solution[\"costs\"].item():,.0f} €')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 1: Built-in Clustering\n",
    "\n",
    "The simplest approach - let flixopt handle clustering internally using tsam.\n",
    "This extracts ALL time series from the FlowSystem and clusters on them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create clustered system using built-in method\n",
    "fs_builtin = flow_system.transform.cluster(\n",
    "    n_clusters=8,  # Find 8 typical days\n",
    "    cluster_duration='1D',\n",
    ")\n",
    "\n",
    "fs_builtin.optimize(solver)\n",
    "print(f'Built-in clustering cost: {fs_builtin.solution[\"costs\"].item():,.0f} €')\n",
    "\n",
    "# Access the clustering parameters\n",
    "params = fs_builtin._clustering_info['parameters']\n",
    "print(f'\\nCluster assignments: {params.cluster_order.values}')\n",
    "print(f'Period length: {params.period_length} timesteps')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 2: External tsam on Data Subset\n",
    "\n",
    "Run tsam yourself on a **subset** of time series data, then pass results to flixopt.\n",
    "\n",
    "This is useful when:\n",
    "- You only want to cluster based on the most important time series (faster tsam)\n",
    "- You want more control over tsam parameters\n",
    "- You want to reuse the same clustering for multiple FlowSystems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tsam.timeseriesaggregation as tsam\n",
    "\n",
    "# Create DataFrame with only the KEY time series\n",
    "# (Much faster than letting flixopt extract ALL time series)\n",
    "clustering_data = pd.DataFrame(\n",
    "    {\n",
    "        'heat_demand': heat_demand.values,\n",
    "        'elec_price': elec_price.values,\n",
    "    },\n",
    "    index=flow_system.timesteps,\n",
    ")\n",
    "\n",
    "print(f'Clustering on {len(clustering_data.columns)} time series (subset of FlowSystem data)')\n",
    "print(f'Columns: {list(clustering_data.columns)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run tsam with custom parameters\n",
    "aggregation = tsam.TimeSeriesAggregation(\n",
    "    clustering_data,\n",
    "    noTypicalPeriods=8,\n",
    "    hoursPerPeriod=24,\n",
    "    resolution=0.25,  # 15-min resolution\n",
    "    clusterMethod='hierarchical',\n",
    ")\n",
    "aggregation.createTypicalPeriods()\n",
    "\n",
    "print(f'tsam cluster order: {aggregation.clusterOrder}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ClusteringParameters with the external tsam aggregation\n",
    "# This allows flixopt to use the tsam results to aggregate ALL FlowSystem data\n",
    "params_external = fx.ClusteringParameters(\n",
    "    n_clusters=8,\n",
    "    cluster_duration='1D',\n",
    "    tsam_aggregation=aggregation,  # Pass the tsam object for data aggregation\n",
    ")\n",
    "\n",
    "print(f'Indices populated: {params_external.has_indices}')\n",
    "print(f'Cluster order: {params_external.cluster_order.values}')\n",
    "print(f'Period length: {params_external.period_length}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply to FlowSystem using add_clustering()\n",
    "fs_external = flow_system.transform.add_clustering(params_external)\n",
    "\n",
    "fs_external.optimize(solver)\n",
    "print(f'External tsam clustering cost: {fs_external.solution[\"costs\"].item():,.0f} €')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 3: Custom Indices\n",
    "\n",
    "Provide your own cluster assignments directly - no tsam required.\n",
    "\n",
    "This is useful when:\n",
    "- You have a custom clustering algorithm\n",
    "- You want to manually define typical periods (e.g., weekdays vs weekends)\n",
    "- You're loading clustering results from another source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom cluster assignments based on day of week\n",
    "# We have 31 days, let's group by weekday pattern\n",
    "n_days = len(flow_system.timesteps) // 96  # 96 timesteps per day (15-min)\n",
    "print(f'Number of days: {n_days}')\n",
    "\n",
    "# Simple pattern: group every 4th day together\n",
    "custom_cluster_order = [i % 8 for i in range(n_days)]\n",
    "\n",
    "# Note: With custom indices (no tsam object), we use aggregate_data=False\n",
    "# because we don't have a tsam to transform the data. This only equalizes\n",
    "# binary (on/off) decisions across similar periods.\n",
    "params_custom = fx.ClusteringParameters(\n",
    "    n_clusters=8,\n",
    "    cluster_duration='1D',\n",
    "    aggregate_data=False,  # No tsam available for data transformation\n",
    "    # Provide indices directly\n",
    "    cluster_order=xr.DataArray(custom_cluster_order, dims=['cluster_period'], name='cluster_order'),\n",
    "    period_length=96,  # 96 timesteps per day (15-min resolution)\n",
    ")\n",
    "\n",
    "print(f'Custom indices set: {params_custom.has_indices}')\n",
    "print(f'Cluster order: {params_custom.cluster_order.values}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply to FlowSystem\n",
    "fs_custom = flow_system.transform.add_clustering(params_custom)\n",
    "\n",
    "fs_custom.optimize(solver)\n",
    "print(f'Custom clustering cost: {fs_custom.solution[\"costs\"].item():,.0f} €')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(\n",
    "    {\n",
    "        'Method': ['Baseline (no clustering)', 'Built-in clustering', 'External tsam (subset)', 'Custom indices'],\n",
    "        'Cost [€]': [\n",
    "            fs_baseline.solution['costs'].item(),\n",
    "            fs_builtin.solution['costs'].item(),\n",
    "            fs_external.solution['costs'].item(),\n",
    "            fs_custom.solution['costs'].item(),\n",
    "        ],\n",
    "    }\n",
    ").set_index('Method')\n",
    "\n",
    "results['Gap vs Baseline [%]'] = (results['Cost [€]'] / results.loc['Baseline (no clustering)', 'Cost [€]'] - 1) * 100\n",
    "results.style.format({'Cost [€]': '{:,.0f}', 'Gap vs Baseline [%]': '{:.2f}'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IO: Save and Reload\n",
    "\n",
    "Clustering indices are automatically saved with the FlowSystem and restored on load."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "\n",
    "# Save clustered FlowSystem\n",
    "with tempfile.TemporaryDirectory() as tmpdir:\n",
    "    path = Path(tmpdir) / 'clustered_system.nc4'\n",
    "    fs_external.to_netcdf(path)\n",
    "    print(f'Saved to: {path}')\n",
    "\n",
    "    # Reload\n",
    "    fs_loaded = fx.FlowSystem.from_netcdf(path)\n",
    "\n",
    "    # Check clustering was restored\n",
    "    params_loaded = fs_loaded._clustering_info['parameters']\n",
    "    print('\\nRestored clustering:')\n",
    "    print(f'  has_indices: {params_loaded.has_indices}')\n",
    "    print(f'  cluster_order: {params_loaded.cluster_order.values}')\n",
    "    print(f'  period_length: {params_loaded.period_length}')\n",
    "\n",
    "    # Solve reloaded system\n",
    "    fs_loaded.optimize(solver)\n",
    "    print(f'\\nReloaded cost: {fs_loaded.solution[\"costs\"].item():,.0f} €')\n",
    "    print(f'Original cost: {fs_external.solution[\"costs\"].item():,.0f} €')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced: Segmentation with External tsam\n",
    "\n",
    "You can also provide segment assignments for intra-period aggregation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run tsam with segmentation on the data subset\n",
    "aggregation_seg = tsam.TimeSeriesAggregation(\n",
    "    clustering_data,\n",
    "    noTypicalPeriods=8,\n",
    "    hoursPerPeriod=24,\n",
    "    resolution=0.25,\n",
    "    segmentation=True,\n",
    "    noSegments=12,  # 12 segments per day (~2 hours each)\n",
    ")\n",
    "aggregation_seg.createTypicalPeriods()\n",
    "\n",
    "# Create parameters with segmentation and tsam for data aggregation\n",
    "params_seg = fx.ClusteringParameters(\n",
    "    n_clusters=8,\n",
    "    cluster_duration='1D',\n",
    "    n_segments=12,\n",
    "    tsam_aggregation=aggregation_seg,  # Pass tsam for data aggregation\n",
    ")\n",
    "\n",
    "print(f'Segment assignment shape: {params_seg.segment_assignment.shape}')\n",
    "print(f'Segment assignment for cluster 0:\\n{params_seg.segment_assignment.sel(cluster=0).values}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply segmented clustering\n",
    "fs_segmented = flow_system.transform.add_clustering(params_seg)\n",
    "fs_segmented.optimize(solver)\n",
    "print(f'Segmented clustering cost: {fs_segmented.solution[\"costs\"].item():,.0f} €')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "| Method | Data Aggregation | When to Use |\n",
    "|--------|------------------|-------------|\n",
    "| `transform.cluster()` | Yes | Default - let flixopt handle everything |\n",
    "| `tsam_aggregation=...` | Yes | External tsam on data subset, with data aggregation |\n",
    "| Direct `cluster_order` | No | Custom algorithms or manual period grouping (binary only) |\n",
    "\n",
    "All methods use `ClusteringParameters` which stores:\n",
    "- `cluster_order`: Which cluster each period belongs to\n",
    "- `period_length`: Timesteps per period\n",
    "- `segment_assignment`: (optional) Segment IDs within each cluster\n",
    "- `tsam_aggregation`: (optional) tsam object for data transformation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
