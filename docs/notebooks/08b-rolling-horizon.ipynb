{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": "# Rolling Horizon\n\nSolve large operational problems by decomposing the time horizon into sequential segments.\n\nThis notebook introduces:\n\n- **Rolling horizon optimization**: Divide time into overlapping segments\n- **State transfer**: Pass storage states and flow history between segments\n- **When to use**: Memory limits, operational planning with limited foresight\n\nWe use a realistic district heating system with CHP, boiler, and storage to demonstrate the approach."
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-13T18:35:42.432171Z",
     "start_time": "2025-12-13T18:35:42.279884Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "flixopt.config.CONFIG"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import timeit\n",
    "\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "import flixopt as fx\n",
    "\n",
    "fx.CONFIG.notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": "## Load Time Series Data\n\nWe use real-world district heating data at 15-minute resolution (two weeks):"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-13T18:35:43.695556Z",
     "start_time": "2025-12-13T18:35:42.878212Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Value based partial slicing on non-monotonic DatetimeIndexes with non-existing keys is not allowed.'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m     notebook_dir = pathlib.Path(\u001b[34m__file__\u001b[39m).parent / \u001b[33m'\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33m__file__\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mdir\u001b[39m() \u001b[38;5;28;01melse\u001b[39;00m pathlib.Path(\u001b[33m'\u001b[39m\u001b[33mdocs/notebooks/data\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      8\u001b[39m data = pd.read_csv(notebook_dir / \u001b[33m'\u001b[39m\u001b[33mZeitreihen2020.csv\u001b[39m\u001b[33m'\u001b[39m, index_col=\u001b[32m0\u001b[39m, parse_dates=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m data = \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m2020-01-01\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m2020-01-14 23:45:00\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m  \u001b[38;5;66;03m# Two weeks\u001b[39;00m\n\u001b[32m     11\u001b[39m timesteps = data.index\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# Extract profiles\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PycharmProjects/flixopt_719231/.venv/lib/python3.11/site-packages/pandas/core/frame.py:4096\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4094\u001b[39m \u001b[38;5;66;03m# Do we have a slicer (on rows)?\u001b[39;00m\n\u001b[32m   4095\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mslice\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m4096\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_getitem_slice\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4098\u001b[39m \u001b[38;5;66;03m# Do we have a (boolean) DataFrame?\u001b[39;00m\n\u001b[32m   4099\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, DataFrame):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PycharmProjects/flixopt_719231/.venv/lib/python3.11/site-packages/pandas/core/generic.py:4371\u001b[39m, in \u001b[36mNDFrame._getitem_slice\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4366\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   4367\u001b[39m \u001b[33;03m__getitem__ for the case where the key is a slice object.\u001b[39;00m\n\u001b[32m   4368\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   4369\u001b[39m \u001b[38;5;66;03m# _convert_slice_indexer to determine if this slice is positional\u001b[39;00m\n\u001b[32m   4370\u001b[39m \u001b[38;5;66;03m#  or label based, and if the latter, convert to positional\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m4371\u001b[39m slobj = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_convert_slice_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkind\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgetitem\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   4372\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(slobj, np.ndarray):\n\u001b[32m   4373\u001b[39m     \u001b[38;5;66;03m# reachable with DatetimeIndex\u001b[39;00m\n\u001b[32m   4374\u001b[39m     indexer = lib.maybe_indices_to_slice(\n\u001b[32m   4375\u001b[39m         slobj.astype(np.intp, copy=\u001b[38;5;28;01mFalse\u001b[39;00m), \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m   4376\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PycharmProjects/flixopt_719231/.venv/lib/python3.11/site-packages/pandas/core/indexes/base.py:4288\u001b[39m, in \u001b[36mIndex._convert_slice_indexer\u001b[39m\u001b[34m(self, key, kind)\u001b[39m\n\u001b[32m   4286\u001b[39m     indexer = key\n\u001b[32m   4287\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m4288\u001b[39m     indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mslice_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4290\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m indexer\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PycharmProjects/flixopt_719231/.venv/lib/python3.11/site-packages/pandas/core/indexes/datetimes.py:697\u001b[39m, in \u001b[36mDatetimeIndex.slice_indexer\u001b[39m\u001b[34m(self, start, end, step)\u001b[39m\n\u001b[32m    694\u001b[39m     in_index &= (end_casted == \u001b[38;5;28mself\u001b[39m).any()\n\u001b[32m    696\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m in_index:\n\u001b[32m--> \u001b[39m\u001b[32m697\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\n\u001b[32m    698\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mValue based partial slicing on non-monotonic DatetimeIndexes \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    699\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mwith non-existing keys is not allowed.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    700\u001b[39m     )\n\u001b[32m    701\u001b[39m indexer = mask.nonzero()[\u001b[32m0\u001b[39m][::step]\n\u001b[32m    702\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(indexer) == \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n",
      "\u001b[31mKeyError\u001b[39m: 'Value based partial slicing on non-monotonic DatetimeIndexes with non-existing keys is not allowed.'"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "\n",
    "# Load time series data (15-min resolution)\n",
    "notebook_dir = pathlib.Path('data')\n",
    "if not notebook_dir.exists():\n",
    "    notebook_dir = (\n",
    "        pathlib.Path(__file__).parent / 'data' if '__file__' in dir() else pathlib.Path('docs/notebooks/data')\n",
    "    )\n",
    "\n",
    "data = pd.read_csv(notebook_dir / 'Zeitreihen2020.csv', index_col=0, parse_dates=True).sort_index()\n",
    "data = data['2020-01-01':'2020-01-14 23:45:00']  # Two weeks\n",
    "\n",
    "timesteps = data.index\n",
    "\n",
    "# Extract profiles\n",
    "electricity_demand = data['P_Netz/MW'].to_numpy()\n",
    "heat_demand = data['Q_Netz/MW'].to_numpy()\n",
    "electricity_price = data['Strompr.€/MWh'].to_numpy()\n",
    "gas_price = data['Gaspr.€/MWh'].to_numpy()\n",
    "\n",
    "print(f'Timesteps: {len(timesteps)} ({len(timesteps) / 96:.0f} days at 15-min resolution)')\n",
    "print(f'Heat demand: {heat_demand.min():.1f} - {heat_demand.max():.1f} MW')\n",
    "print(f'Electricity price: {electricity_price.min():.1f} - {electricity_price.max():.1f} €/MWh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_system(timesteps, heat_demand, electricity_demand, electricity_price, gas_price):\n",
    "    \"\"\"Build a district heating system with CHP, boiler, and storage.\"\"\"\n",
    "    fs = fx.FlowSystem(timesteps)\n",
    "\n",
    "    # Effects\n",
    "\n",
    "    # Buses\n",
    "    fs.add_elements(\n",
    "        fx.Bus('Electricity'),\n",
    "        fx.Bus('Heat'),\n",
    "        fx.Bus('Gas'),\n",
    "        fx.Bus('Coal'),\n",
    "        fx.Effect('costs', '€', 'Total Costs', is_standard=True, is_objective=True),\n",
    "        fx.Effect('CO2', 'kg', 'CO2 Emissions'),\n",
    "        fx.linear_converters.CHP(\n",
    "            'CHP',\n",
    "            thermal_efficiency=0.58,\n",
    "            electrical_efficiency=0.22,\n",
    "            status_parameters=fx.StatusParameters(effects_per_startup=24000),\n",
    "            electrical_flow=fx.Flow('P_el', bus='Electricity', size=200),\n",
    "            thermal_flow=fx.Flow('Q_th', bus='Heat', size=200),\n",
    "            fuel_flow=fx.Flow('Q_fu', bus='Coal', size=288, relative_minimum=87 / 288, previous_flow_rate=100),\n",
    "        ),\n",
    "        fx.linear_converters.Boiler(\n",
    "            'Boiler',\n",
    "            thermal_efficiency=0.85,\n",
    "            thermal_flow=fx.Flow('Q_th', bus='Heat'),\n",
    "            fuel_flow=fx.Flow(\n",
    "                'Q_fu',\n",
    "                bus='Gas',\n",
    "                size=95,\n",
    "                relative_minimum=12 / 95,\n",
    "                previous_flow_rate=20,\n",
    "                status_parameters=fx.StatusParameters(effects_per_startup=1000),\n",
    "            ),\n",
    "        ),\n",
    "        fx.Storage(\n",
    "            'Storage',\n",
    "            capacity_in_flow_hours=684,\n",
    "            initial_charge_state=137,\n",
    "            minimal_final_charge_state=137,\n",
    "            maximal_final_charge_state=158,\n",
    "            eta_charge=1,\n",
    "            eta_discharge=1,\n",
    "            relative_loss_per_hour=0.001,\n",
    "            prevent_simultaneous_charge_and_discharge=True,\n",
    "            charging=fx.Flow('Charge', size=137, bus='Heat'),\n",
    "            discharging=fx.Flow('Discharge', size=158, bus='Heat'),\n",
    "        ),\n",
    "        fx.Source(\n",
    "            'GasGrid',\n",
    "            outputs=[fx.Flow('Q_Gas', bus='Gas', size=1000, effects_per_flow_hour={'costs': gas_price, 'CO2': 0.3})],\n",
    "        ),\n",
    "        fx.Source(\n",
    "            'CoalSupply',\n",
    "            outputs=[fx.Flow('Q_Coal', bus='Coal', size=1000, effects_per_flow_hour={'costs': 4.6, 'CO2': 0.3})],\n",
    "        ),\n",
    "        fx.Source(\n",
    "            'GridBuy',\n",
    "            outputs=[\n",
    "                fx.Flow(\n",
    "                    'P_el',\n",
    "                    bus='Electricity',\n",
    "                    size=1000,\n",
    "                    effects_per_flow_hour={'costs': electricity_price + 0.5, 'CO2': 0.3},\n",
    "                )\n",
    "            ],\n",
    "        ),\n",
    "        fx.Sink(\n",
    "            'GridSell',\n",
    "            inputs=[fx.Flow('P_el', bus='Electricity', size=1000, effects_per_flow_hour=-(electricity_price - 0.5))],\n",
    "        ),\n",
    "        fx.Sink('HeatDemand', inputs=[fx.Flow('Q_th', bus='Heat', size=1, fixed_relative_profile=heat_demand)]),\n",
    "        fx.Sink(\n",
    "            'ElecDemand', inputs=[fx.Flow('P_el', bus='Electricity', size=1, fixed_relative_profile=electricity_demand)]\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    return fs\n",
    "\n",
    "\n",
    "flow_system = build_system(timesteps, heat_demand, electricity_demand, electricity_price, gas_price)\n",
    "print(f'System: {len(timesteps)} timesteps')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## Full Optimization (Baseline)\n",
    "\n",
    "First, solve the full problem as a baseline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "solver = fx.solvers.HighsSolver()\n",
    "\n",
    "start = timeit.default_timer()\n",
    "fs_full = flow_system.copy()\n",
    "fs_full.optimize(solver)\n",
    "time_full = timeit.default_timer() - start\n",
    "\n",
    "print(f'Full optimization: {time_full:.2f} seconds')\n",
    "print(f'Cost: {fs_full.solution[\"costs\"].item():,.0f} €')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": "## Rolling Horizon Optimization\n\nThe `optimize.rolling_horizon()` method divides the time horizon into segments that are solved sequentially:\n\n```\nFull horizon:  |---------- 1344 timesteps (14 days) ----------|\n                \nSegment 1:     |==== 192 (2 days) ====|-- overlap --|\nSegment 2:                |==== 192 (2 days) ====|-- overlap --|\nSegment 3:                              |==== 192 (2 days) ====|-- overlap --|\n...                                                  \n```\n\nKey parameters:\n- **horizon**: Timesteps per segment (excluding overlap)\n- **overlap**: Additional lookahead timesteps (improves storage optimization)\n- **nr_of_previous_values**: Flow history transferred between segments"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timeit.default_timer()\n",
    "fs_rolling = flow_system.copy()\n",
    "segments = fs_rolling.optimize.rolling_horizon(\n",
    "    solver,\n",
    "    horizon=192,  # 2-day segments (192 timesteps at 15-min resolution)\n",
    "    overlap=48,  # 12-hour lookahead\n",
    ")\n",
    "time_rolling = timeit.default_timer() - start\n",
    "\n",
    "print(f'Rolling horizon: {time_rolling:.2f} seconds ({len(segments)} segments)')\n",
    "print(f'Cost: {fs_rolling.solution[\"costs\"].item():,.0f} €')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "## Compare Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_full = fs_full.solution['costs'].item()\n",
    "cost_rolling = fs_rolling.solution['costs'].item()\n",
    "cost_gap = (cost_rolling - cost_full) / cost_full * 100\n",
    "\n",
    "results = pd.DataFrame(\n",
    "    {\n",
    "        'Method': ['Full optimization', 'Rolling horizon'],\n",
    "        'Time [s]': [time_full, time_rolling],\n",
    "        'Cost [€]': [cost_full, cost_rolling],\n",
    "        'Cost Gap [%]': [0.0, cost_gap],\n",
    "    }\n",
    ").set_index('Method')\n",
    "\n",
    "results.style.format({'Time [s]': '{:.2f}', 'Cost [€]': '{:,.0f}', 'Cost Gap [%]': '{:.2f}'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## Visualize: Heat Balance Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs_full.statistics.plot.balance('Heat').figure.update_layout(title='Heat Balance (Full)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs_rolling.statistics.plot.balance('Heat').figure.update_layout(title='Heat Balance (Rolling)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "## Storage State Continuity\n",
    "\n",
    "Rolling horizon transfers storage charge states between segments to ensure continuity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(\n",
    "    rows=2, cols=1, shared_xaxes=True, vertical_spacing=0.1, subplot_titles=['Full Optimization', 'Rolling Horizon']\n",
    ")\n",
    "\n",
    "# Full optimization\n",
    "charge_full = fs_full.solution['Storage|charge_state'].values[:-1]  # Drop final value\n",
    "fig.add_trace(go.Scatter(x=timesteps, y=charge_full, name='Full', line=dict(color='blue')), row=1, col=1)\n",
    "\n",
    "# Rolling horizon\n",
    "charge_rolling = fs_rolling.solution['Storage|charge_state'].values[:-1]\n",
    "fig.add_trace(go.Scatter(x=timesteps, y=charge_rolling, name='Rolling', line=dict(color='orange')), row=2, col=1)\n",
    "\n",
    "fig.update_yaxes(title_text='Charge State [MWh]', row=1, col=1)\n",
    "fig.update_yaxes(title_text='Charge State [MWh]', row=2, col=1)\n",
    "fig.update_layout(height=400, showlegend=False)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "## Inspect Individual Segments\n",
    "\n",
    "The method returns the individual segment FlowSystems, which can be inspected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Number of segments: {len(segments)}')\n",
    "print()\n",
    "for i, seg in enumerate(segments):\n",
    "    start_time = seg.timesteps[0]\n",
    "    end_time = seg.timesteps[-1]\n",
    "    cost = seg.solution['costs'].item()\n",
    "    print(\n",
    "        f'Segment {i + 1}: {start_time.strftime(\"%Y-%m-%d %H:%M\")} → {end_time.strftime(\"%Y-%m-%d %H:%M\")} | Cost: {cost:,.0f} €'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "## Effect of Overlap\n",
    "\n",
    "The overlap parameter provides lookahead for storage optimization. Let's compare different overlap values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "overlaps = [0, 24, 48, 96]  # 0, 6h, 12h, 24h lookahead\n",
    "overlap_results = []\n",
    "\n",
    "for overlap in overlaps:\n",
    "    fs = flow_system.copy()\n",
    "    start = timeit.default_timer()\n",
    "    fs.optimize.rolling_horizon(solver, horizon=192, overlap=overlap)\n",
    "    elapsed = timeit.default_timer() - start\n",
    "    cost = fs.solution['costs'].item()\n",
    "    gap = (cost - cost_full) / cost_full * 100\n",
    "    overlap_results.append(\n",
    "        {'Overlap': f'{overlap} ({overlap * 15 / 60:.0f}h)', 'Time [s]': elapsed, 'Cost [€]': cost, 'Gap [%]': gap}\n",
    "    )\n",
    "\n",
    "pd.DataFrame(overlap_results).style.format({'Time [s]': '{:.2f}', 'Cost [€]': '{:,.0f}', 'Gap [%]': '{:.2f}'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "## When to Use Rolling Horizon\n",
    "\n",
    "| Use Case | Recommendation |\n",
    "|----------|----------------|\n",
    "| **Memory limits** | Large problems that exceed available memory |\n",
    "| **Operational planning** | When limited foresight is realistic |\n",
    "| **Quick approximate solutions** | Faster than full optimization |\n",
    "| **Investment decisions** | Use full optimization instead |\n",
    "\n",
    "### Limitations\n",
    "\n",
    "- **No investments**: `InvestParameters` are not supported (raises error)\n",
    "- **Suboptimal storage**: Limited foresight may miss long-term storage opportunities\n",
    "- **Global constraints**: `flow_hours_max` etc. cannot be enforced globally"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "## API Reference\n",
    "\n",
    "```python\n",
    "segments = flow_system.optimize.rolling_horizon(\n",
    "    solver,              # Solver instance\n",
    "    horizon=192,         # Timesteps per segment (e.g., 2 days at 15-min resolution)\n",
    "    overlap=48,          # Additional lookahead timesteps (e.g., 12 hours)\n",
    "    nr_of_previous_values=1,  # Flow history for uptime/downtime tracking\n",
    ")\n",
    "\n",
    "# Combined solution on original FlowSystem\n",
    "flow_system.solution['costs'].item()\n",
    "\n",
    "# Individual segment solutions\n",
    "for seg in segments:\n",
    "    print(seg.solution['costs'].item())\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "You learned how to:\n",
    "\n",
    "- Use **`optimize.rolling_horizon()`** to decompose large problems\n",
    "- Choose **horizon** and **overlap** parameters\n",
    "- Understand the **trade-offs** vs. full optimization\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **Rolling horizon** is useful for memory-limited or operational planning problems\n",
    "2. **Overlap** improves solution quality at the cost of computation time\n",
    "3. **Storage states** are automatically transferred between segments\n",
    "4. Use **full optimization** for investment decisions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
