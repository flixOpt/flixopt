{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Intra-Period Segmentation with `cluster()`\n",
    "\n",
    "Reduce timesteps within each typical period using segmentation.\n",
    "\n",
    "This notebook demonstrates:\n",
    "\n",
    "- **Segmentation**: Aggregate timesteps within each cluster into fewer segments\n",
    "- **Variable durations**: Each segment can have different duration (hours)\n",
    "- **Combined reduction**: Use clustering AND segmentation for maximum speedup\n",
    "- **Expansion**: Map segmented results back to original timesteps\n",
    "\n",
    "!!! note \"Requirements\"\n",
    "    This notebook requires the `tsam` package: `pip install tsam`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "import flixopt as fx\n",
    "\n",
    "fx.CONFIG.notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## What is Segmentation?\n",
    "\n",
    "**Clustering** groups similar time periods (e.g., days) into representative clusters.\n",
    "\n",
    "**Segmentation** goes further by aggregating timesteps *within* each cluster into fewer segments with variable durations.\n",
    "\n",
    "```\n",
    "Original:     | Day 1 (24h) | Day 2 (24h) | Day 3 (24h) | ... | Day 365 (24h) |\n",
    "                 ↓               ↓               ↓                   ↓\n",
    "Clustered:    | Typical Day A (24h) | Typical Day B (24h) | Typical Day C (24h) |\n",
    "                 ↓                      ↓                      ↓\n",
    "Segmented:    | Seg1 (4h) | Seg2 (8h) | Seg3 (8h) | Seg4 (4h) |  (per typical day)\n",
    "```\n",
    "\n",
    "This can dramatically reduce problem size:\n",
    "- **Original**: 365 days × 24 hours = 8,760 timesteps\n",
    "- **Clustered (8 days)**: 8 × 24 = 192 timesteps\n",
    "- **Segmented (6 segments)**: 8 × 6 = 48 timesteps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## Create the FlowSystem\n",
    "\n",
    "We use a district heating system with one month of data at 15-min resolution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.generate_example_systems import create_district_heating_system\n",
    "\n",
    "flow_system = create_district_heating_system()\n",
    "flow_system.connect_and_transform()\n",
    "\n",
    "print(f'Timesteps: {len(flow_system.timesteps)}')\n",
    "print(f'Duration: {(flow_system.timesteps[-1] - flow_system.timesteps[0]).days + 1} days')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize input data\n",
    "heat_demand = flow_system.components['HeatDemand'].inputs[0].fixed_relative_profile\n",
    "heat_demand.plotly.line(title='Heat Demand Profile')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## Full Optimization (Baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "solver = fx.solvers.HighsSolver(mip_gap=0.01)\n",
    "\n",
    "start = timeit.default_timer()\n",
    "fs_full = flow_system.copy()\n",
    "fs_full.name = 'Full Optimization'\n",
    "fs_full.optimize(solver)\n",
    "time_full = timeit.default_timer() - start\n",
    "\n",
    "print(f'Full optimization: {time_full:.2f} seconds')\n",
    "print(f'Total cost: {fs_full.solution[\"costs\"].item():,.0f} €')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## Clustering with Segmentation\n",
    "\n",
    "Use `SegmentConfig` to enable intra-period segmentation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsam import ExtremeConfig, SegmentConfig\n",
    "\n",
    "start = timeit.default_timer()\n",
    "\n",
    "# Cluster into 8 typical days with 6 segments each\n",
    "fs_segmented = flow_system.transform.cluster(\n",
    "    n_clusters=8,\n",
    "    cluster_duration='1D',\n",
    "    segments=SegmentConfig(n_segments=6),  # 6 segments per day instead of 96 quarter-hours\n",
    "    extremes=ExtremeConfig(method='new_cluster', max_value=['HeatDemand(Q_th)|fixed_relative_profile']),\n",
    ")\n",
    "\n",
    "time_clustering = timeit.default_timer() - start\n",
    "\n",
    "print(f'Clustering time: {time_clustering:.2f} seconds')\n",
    "print(f'Original timesteps: {len(flow_system.timesteps)}')\n",
    "print(\n",
    "    f'Segmented timesteps: {len(fs_segmented.timesteps)} × {len(fs_segmented.clusters)} clusters = {len(fs_segmented.timesteps) * len(fs_segmented.clusters)}'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "## Understanding Segmentation Properties\n",
    "\n",
    "After segmentation, the clustering object has additional properties:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering = fs_segmented.clustering\n",
    "\n",
    "print('Segmentation Properties:')\n",
    "print(f'  is_segmented: {clustering.is_segmented}')\n",
    "print(f'  n_segments: {clustering.n_segments}')\n",
    "print(f'  n_clusters: {clustering.n_clusters}')\n",
    "print(f'  timesteps_per_cluster (original): {clustering.timesteps_per_cluster}')\n",
    "print(f'\\nTime dimension uses RangeIndex: {type(fs_segmented.timesteps)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## Variable Timestep Durations\n",
    "\n",
    "Each segment has a different duration, determined by how many original timesteps it represents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Timestep duration is now a DataArray with (cluster, time) dimensions\n",
    "timestep_duration = fs_segmented.timestep_duration\n",
    "\n",
    "print(f'Timestep duration shape: {dict(timestep_duration.sizes)}')\n",
    "print('\\nSegment durations for cluster 0:')\n",
    "cluster_0_durations = timestep_duration.sel(cluster=0).values\n",
    "for i, dur in enumerate(cluster_0_durations):\n",
    "    print(f'  Segment {i}: {dur:.2f} hours')\n",
    "print(f'  Total: {cluster_0_durations.sum():.2f} hours (should be 24h)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize segment durations across clusters\n",
    "duration_df = timestep_duration.to_dataframe('duration').reset_index()\n",
    "fig = px.bar(\n",
    "    duration_df,\n",
    "    x='time',\n",
    "    y='duration',\n",
    "    facet_col='cluster',\n",
    "    facet_col_wrap=4,\n",
    "    title='Segment Durations by Cluster',\n",
    "    labels={'time': 'Segment', 'duration': 'Duration [hours]'},\n",
    ")\n",
    "fig.update_layout(height=400)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "## Optimize the Segmented System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timeit.default_timer()\n",
    "fs_segmented.optimize(solver)\n",
    "time_segmented = timeit.default_timer() - start\n",
    "\n",
    "print(f'Segmented optimization: {time_segmented:.2f} seconds')\n",
    "print(f'Total cost: {fs_segmented.solution[\"costs\"].item():,.0f} €')\n",
    "print(f'\\nSpeedup vs full: {time_full / (time_clustering + time_segmented):.1f}x')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "## Compare Clustering Quality\n",
    "\n",
    "View how well the segmented data represents the original:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duration curves show how well the distribution is preserved\n",
    "fs_segmented.clustering.plot.compare(kind='duration_curve')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clustering quality metrics\n",
    "fs_segmented.clustering.metrics.to_dataframe().style.format('{:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "## Expand to Original Timesteps\n",
    "\n",
    "Use `expand()` to map the segmented solution back to all original timesteps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timeit.default_timer()\n",
    "fs_expanded = fs_segmented.transform.expand()\n",
    "time_expand = timeit.default_timer() - start\n",
    "\n",
    "print(f'Expansion time: {time_expand:.3f} seconds')\n",
    "print(f'Expanded timesteps: {len(fs_expanded.timesteps)}')\n",
    "print(f'Objective preserved: {fs_expanded.solution[\"costs\"].item():,.0f} €')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare flow rates: Full vs Expanded\n",
    "import xarray as xr\n",
    "\n",
    "flow_var = 'CHP(Q_th)|flow_rate'\n",
    "comparison_ds = xr.concat(\n",
    "    [fs_full.solution[flow_var], fs_expanded.solution[flow_var]],\n",
    "    dim=pd.Index(['Full', 'Expanded'], name='method'),\n",
    ")\n",
    "comparison_ds.plotly.line(color='method', title='CHP Heat Output Comparison')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "## Two-Stage Workflow with Segmentation\n",
    "\n",
    "For investment optimization, use segmentation for fast sizing, then dispatch at full resolution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stage 1: Sizing with segmentation (already done)\n",
    "SAFETY_MARGIN = 1.05\n",
    "sizes_with_margin = {name: float(size.item()) * SAFETY_MARGIN for name, size in fs_segmented.statistics.sizes.items()}\n",
    "\n",
    "print('Optimized sizes with safety margin:')\n",
    "for name, size in sizes_with_margin.items():\n",
    "    print(f'  {name}: {size:.1f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stage 2: Full resolution dispatch with fixed sizes\n",
    "start = timeit.default_timer()\n",
    "fs_dispatch = flow_system.transform.fix_sizes(sizes_with_margin)\n",
    "fs_dispatch.name = 'Two-Stage'\n",
    "fs_dispatch.optimize(solver)\n",
    "time_dispatch = timeit.default_timer() - start\n",
    "\n",
    "print(f'Dispatch time: {time_dispatch:.2f} seconds')\n",
    "print(f'Final cost: {fs_dispatch.solution[\"costs\"].item():,.0f} €')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "## Compare Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_segmented = time_clustering + time_segmented\n",
    "total_two_stage = total_segmented + time_dispatch\n",
    "\n",
    "results = {\n",
    "    'Full (baseline)': {\n",
    "        'Time [s]': time_full,\n",
    "        'Cost [€]': fs_full.solution['costs'].item(),\n",
    "        'CHP': fs_full.statistics.sizes['CHP(Q_th)'].item(),\n",
    "        'Boiler': fs_full.statistics.sizes['Boiler(Q_th)'].item(),\n",
    "        'Storage': fs_full.statistics.sizes['Storage'].item(),\n",
    "    },\n",
    "    'Segmented (8×6)': {\n",
    "        'Time [s]': total_segmented,\n",
    "        'Cost [€]': fs_segmented.solution['costs'].item(),\n",
    "        'CHP': fs_segmented.statistics.sizes['CHP(Q_th)'].item(),\n",
    "        'Boiler': fs_segmented.statistics.sizes['Boiler(Q_th)'].item(),\n",
    "        'Storage': fs_segmented.statistics.sizes['Storage'].item(),\n",
    "    },\n",
    "    'Two-Stage': {\n",
    "        'Time [s]': total_two_stage,\n",
    "        'Cost [€]': fs_dispatch.solution['costs'].item(),\n",
    "        'CHP': sizes_with_margin['CHP(Q_th)'],\n",
    "        'Boiler': sizes_with_margin['Boiler(Q_th)'],\n",
    "        'Storage': sizes_with_margin['Storage'],\n",
    "    },\n",
    "}\n",
    "\n",
    "comparison = pd.DataFrame(results).T\n",
    "baseline_cost = comparison.loc['Full (baseline)', 'Cost [€]']\n",
    "baseline_time = comparison.loc['Full (baseline)', 'Time [s]']\n",
    "comparison['Cost Gap [%]'] = ((comparison['Cost [€]'] - baseline_cost) / abs(baseline_cost) * 100).round(2)\n",
    "comparison['Speedup'] = (baseline_time / comparison['Time [s]']).round(1)\n",
    "\n",
    "comparison.style.format(\n",
    "    {\n",
    "        'Time [s]': '{:.2f}',\n",
    "        'Cost [€]': '{:,.0f}',\n",
    "        'CHP': '{:.1f}',\n",
    "        'Boiler': '{:.1f}',\n",
    "        'Storage': '{:.0f}',\n",
    "        'Cost Gap [%]': '{:.2f}',\n",
    "        'Speedup': '{:.1f}x',\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "## Segmentation with Multi-Period Systems\n",
    "\n",
    "Segmentation works with multi-period systems (multiple years, scenarios).\n",
    "Each period/scenario combination is segmented independently:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.generate_example_systems import create_multiperiod_system\n",
    "\n",
    "fs_multi = create_multiperiod_system()\n",
    "# Use first week only for faster demo\n",
    "fs_multi = fs_multi.transform.isel(time=slice(0, 168))\n",
    "\n",
    "print(f'Periods: {list(fs_multi.periods.values)}')\n",
    "print(f'Scenarios: {list(fs_multi.scenarios.values)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster with segmentation\n",
    "fs_multi_seg = fs_multi.transform.cluster(\n",
    "    n_clusters=3,\n",
    "    cluster_duration='1D',\n",
    "    segments=SegmentConfig(n_segments=6),\n",
    "    extremes=ExtremeConfig(method='new_cluster', max_value=['Building(Heat)|fixed_relative_profile']),\n",
    ")\n",
    "\n",
    "print(f'Original: {len(fs_multi.timesteps)} timesteps')\n",
    "print(f'Segmented: {len(fs_multi_seg.timesteps)} × {len(fs_multi_seg.clusters)} clusters')\n",
    "print(f'is_segmented: {fs_multi_seg.clustering.is_segmented}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster assignments have period/scenario dimensions\n",
    "fs_multi_seg.clustering.cluster_assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize and expand\n",
    "fs_multi_seg.optimize(solver)\n",
    "fs_multi_expanded = fs_multi_seg.transform.expand()\n",
    "\n",
    "print(f'Expanded timesteps: {len(fs_multi_expanded.timesteps)}')\n",
    "print(f'Objective: {fs_multi_expanded.solution[\"objective\"].item():,.0f} €')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "## API Reference\n",
    "\n",
    "### SegmentConfig Parameters\n",
    "\n",
    "```python\n",
    "from tsam import SegmentConfig\n",
    "\n",
    "segments = SegmentConfig(\n",
    "    n_segments=6,              # Number of segments per cluster period\n",
    "    representation_method='mean',  # How to represent segment values ('mean', 'medoid', etc.)\n",
    ")\n",
    "```\n",
    "\n",
    "### Segmentation Properties\n",
    "\n",
    "After segmentation, `fs.clustering` has additional properties:\n",
    "\n",
    "| Property | Description |\n",
    "|----------|-------------|\n",
    "| `is_segmented` | `True` if segmentation was used |\n",
    "| `n_segments` | Number of segments per cluster |\n",
    "| `timesteps_per_cluster` | Original timesteps per cluster (before segmentation) |\n",
    "\n",
    "### Timestep Duration\n",
    "\n",
    "For segmented systems, `fs.timestep_duration` is a DataArray with `(cluster, time)` dimensions:\n",
    "\n",
    "```python\n",
    "# Each segment has different duration\n",
    "fs_segmented.timestep_duration  # Shape: (n_clusters, n_segments)\n",
    "\n",
    "# Sum should equal original period duration\n",
    "fs_segmented.timestep_duration.sum('time')  # Should be 24h for daily clusters\n",
    "```\n",
    "\n",
    "### Example Workflow\n",
    "\n",
    "```python\n",
    "from tsam import ExtremeConfig, SegmentConfig\n",
    "\n",
    "# Cluster with segmentation\n",
    "fs_segmented = flow_system.transform.cluster(\n",
    "    n_clusters=8,\n",
    "    cluster_duration='1D',\n",
    "    segments=SegmentConfig(n_segments=6),\n",
    "    extremes=ExtremeConfig(method='new_cluster', max_value=['Demand|profile']),\n",
    ")\n",
    "\n",
    "# Optimize\n",
    "fs_segmented.optimize(solver)\n",
    "\n",
    "# Expand back to original timesteps\n",
    "fs_expanded = fs_segmented.transform.expand()\n",
    "\n",
    "# Two-stage workflow\n",
    "sizes = {k: v.item() * 1.05 for k, v in fs_segmented.statistics.sizes.items()}\n",
    "fs_dispatch = flow_system.transform.fix_sizes(sizes)\n",
    "fs_dispatch.optimize(solver)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "You learned how to:\n",
    "\n",
    "- Use **`SegmentConfig`** to enable intra-period segmentation\n",
    "- Work with **variable timestep durations** for each segment\n",
    "- **Combine clustering and segmentation** for maximum problem size reduction\n",
    "- **Expand segmented solutions** back to original timesteps\n",
    "- Use segmentation with **multi-period systems**\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **Segmentation reduces problem size further**: From 8×24=192 to 8×6=48 timesteps\n",
    "2. **Variable durations preserve accuracy**: Important periods get more timesteps\n",
    "3. **Works with multi-period**: Each period/scenario is segmented independently\n",
    "4. **expand() works correctly**: Maps segment values to all original timesteps\n",
    "5. **Two-stage is still recommended**: Use segmentation for sizing, full resolution for dispatch\n",
    "\n",
    "### Trade-offs\n",
    "\n",
    "| More Segments | Fewer Segments |\n",
    "|---------------|----------------|\n",
    "| Higher accuracy | Lower accuracy |\n",
    "| Slower solve | Faster solve |\n",
    "| More memory | Less memory |\n",
    "\n",
    "Start with 6-12 segments and adjust based on your accuracy needs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
